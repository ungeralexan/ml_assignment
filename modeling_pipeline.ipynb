{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ML Modeling Pipeline: Strategic Voucher Targeting\n",
        "\n",
        "This notebook implements an end-to-end modeling workflow for maximizing expected revenue from sending €5 vouchers to customers after their first purchase.\n",
        "\n",
        "**Business Objective**: Optimize the decision to send vouchers to maximize net revenue.\n",
        "\n",
        "**Key Decision Rule**: Send voucher when predicted probability of reorder (target90=1) is **below** a threshold, i.e., send to customers predicted as **not reordering**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Imports and Config\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Scikit-learn\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import (\n",
        "    RandomForestClassifier,\n",
        "    GradientBoostingClassifier,\n",
        "    AdaBoostClassifier,\n",
        "    HistGradientBoostingClassifier\n",
        ")\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.calibration import calibration_curve\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    roc_auc_score,\n",
        "    confusion_matrix,\n",
        "    classification_report,\n",
        "    ConfusionMatrixDisplay\n",
        ")\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "\n",
        "# Optuna for hyperparameter tuning\n",
        "try:\n",
        "    import optuna\n",
        "    OPTUNA_AVAILABLE = True\n",
        "except ImportError:\n",
        "    OPTUNA_AVAILABLE = False\n",
        "    print(\"Warning: Optuna not available. Hyperparameter tuning will be limited.\")\n",
        "\n",
        "# XGBoost\n",
        "try:\n",
        "    import xgboost as xgb\n",
        "    XGBOOST_AVAILABLE = True\n",
        "except ImportError:\n",
        "    XGBOOST_AVAILABLE = False\n",
        "    print(\"Warning: XGBoost not available. Using HistGradientBoostingClassifier as fallback.\")\n",
        "\n",
        "# Joblib for model persistence\n",
        "import joblib\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)\n",
        "\n",
        "# Display options\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "print(\"Imports completed successfully.\")\n",
        "print(f\"Optuna available: {OPTUNA_AVAILABLE}\")\n",
        "print(f\"XGBoost available: {XGBOOST_AVAILABLE}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Loading / Inputs\n",
        "\n",
        "Load the preprocessed datasets. If running this notebook standalone, we'll need to run the preprocessing pipeline first. Otherwise, we assume `X_train_df`, `X_val_df`, `X_test_df`, `y_train`, and `y_val` are already available in memory.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if preprocessed data exists in memory\n",
        "try:\n",
        "    # Try to access the preprocessed data\n",
        "    _ = X_train_df.shape\n",
        "    _ = X_val_df.shape\n",
        "    _ = X_test_df.shape\n",
        "    _ = y_train.shape\n",
        "    _ = y_val.shape\n",
        "    print(\"Using preprocessed data from memory.\")\n",
        "    data_loaded = True\n",
        "except NameError:\n",
        "    print(\"Preprocessed data not found in memory. Loading and preprocessing from raw files...\")\n",
        "    data_loaded = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if not data_loaded:\n",
        "    # Load raw data\n",
        "    train = pd.read_csv('train.csv', sep=';', low_memory=False)\n",
        "    test = pd.read_csv('test.csv', sep=';', low_memory=False)\n",
        "    \n",
        "    # Feature engineering function (from preprocessing notebook)\n",
        "    def engineer_features(df: pd.DataFrame) -> pd.DataFrame:\n",
        "        \"\"\"Apply feature engineering steps.\"\"\"\n",
        "        out = df.copy()\n",
        "        \n",
        "        # Drop columns\n",
        "        out.drop(columns=[\"customernumber\", \"points\", \"delivpostcode\"], inplace=True, errors=\"ignore\")\n",
        "        \n",
        "        # Advertising indicator\n",
        "        if \"advertisingdatacode\" in out.columns:\n",
        "            out[\"has_ad_code\"] = out[\"advertisingdatacode\"].notna().astype(int)\n",
        "            out.drop(columns=[\"advertisingdatacode\"], inplace=True)\n",
        "        \n",
        "        # Parse datetime columns\n",
        "        for c in [\"date\", \"datecreated\", \"deliverydatepromised\", \"deliverydatereal\"]:\n",
        "            if c in out.columns:\n",
        "                out[c] = pd.to_datetime(out[c], errors=\"coerce\")\n",
        "        \n",
        "        # Engineered time features\n",
        "        out[\"account_age_days\"] = (out[\"date\"] - out[\"datecreated\"]).dt.days\n",
        "        out[\"order_weekday\"] = out[\"date\"].dt.weekday\n",
        "        out[\"order_month\"] = out[\"date\"].dt.month\n",
        "        out[\"promised_delivery_weekday\"] = out[\"deliverydatepromised\"].dt.weekday\n",
        "        out[\"promised_delivery_month\"] = out[\"deliverydatepromised\"].dt.month\n",
        "        out[\"delivery_difference\"] = (out[\"deliverydatereal\"] - out[\"deliverydatepromised\"]).dt.days\n",
        "        \n",
        "        # Drop raw datetime columns\n",
        "        out.drop(columns=[\"date\", \"datecreated\", \"deliverydatepromised\", \"deliverydatereal\"], \n",
        "                inplace=True, errors=\"ignore\")\n",
        "        \n",
        "        # Product diversity\n",
        "        w_cols = [f\"w{i}\" for i in range(11)]\n",
        "        existing_w = [c for c in w_cols if c in out.columns]\n",
        "        out[\"product_diversity\"] = (out[existing_w] > 0).sum(axis=1)\n",
        "        \n",
        "        # Drop invoicepostcode\n",
        "        out.drop(columns=[\"invoicepostcode\"], inplace=True, errors=\"ignore\")\n",
        "        \n",
        "        return out\n",
        "    \n",
        "    # Apply feature engineering\n",
        "    train_fe = engineer_features(train)\n",
        "    test_fe = engineer_features(test)\n",
        "    \n",
        "    # Split train/val\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    X = train_fe.drop(columns=[\"target90\"])\n",
        "    y = train_fe[\"target90\"]\n",
        "    \n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        X, y, test_size=0.25, random_state=RANDOM_STATE, stratify=y\n",
        "    )\n",
        "    \n",
        "    # Preprocessing pipeline\n",
        "    from sklearn.compose import ColumnTransformer\n",
        "    from sklearn.pipeline import Pipeline as SKPipeline\n",
        "    from sklearn.preprocessing import OneHotEncoder\n",
        "    from sklearn.impute import SimpleImputer\n",
        "    \n",
        "    w_cols = [f\"w{i}\" for i in range(11)]\n",
        "    cat_cols = [\n",
        "        \"salutation\", \"title\", \"domain\", \"newsletter\", \"model\",\n",
        "        \"paymenttype\", \"deliverytype\", \"voucher\", \"gift\", \"entry\", \"shippingcosts\"\n",
        "    ]\n",
        "    num_cols = [\n",
        "        \"case\", \"numberitems\", \"weight\", \"remi\", \"cancel\", \"used\",\n",
        "        \"has_ad_code\", \"account_age_days\", \"order_weekday\", \"order_month\",\n",
        "        \"promised_delivery_weekday\", \"promised_delivery_month\",\n",
        "        \"delivery_difference\", \"product_diversity\", *w_cols\n",
        "    ]\n",
        "    \n",
        "    numeric_pipe = SKPipeline(steps=[(\"imputer\", SimpleImputer(strategy=\"median\"))])\n",
        "    categorical_pipe = SKPipeline(steps=[\n",
        "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "        (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
        "    ])\n",
        "    \n",
        "    preprocess = ColumnTransformer(\n",
        "        transformers=[\n",
        "            (\"num\", numeric_pipe, num_cols),\n",
        "            (\"cat\", categorical_pipe, cat_cols),\n",
        "        ],\n",
        "        remainder=\"drop\"\n",
        "    )\n",
        "    \n",
        "    # Fit and transform\n",
        "    X_train_t = preprocess.fit_transform(X_train)\n",
        "    X_val_t = preprocess.transform(X_val)\n",
        "    X_test_t = preprocess.transform(test_fe)\n",
        "    \n",
        "    # Get feature names\n",
        "    num_names = num_cols\n",
        "    ohe = preprocess.named_transformers_[\"cat\"].named_steps[\"ohe\"]\n",
        "    cat_names = ohe.get_feature_names_out(cat_cols).tolist()\n",
        "    feature_names = num_names + cat_names\n",
        "    \n",
        "    # Create DataFrames\n",
        "    X_train_df = pd.DataFrame(X_train_t, columns=feature_names, index=X_train.index)\n",
        "    X_val_df = pd.DataFrame(X_val_t, columns=feature_names, index=X_val.index)\n",
        "    X_test_df = pd.DataFrame(X_test_t, columns=feature_names, index=test_fe.index)\n",
        "    \n",
        "    print(\"Data loaded and preprocessed successfully.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Quality checks\n",
        "assert X_train_df.columns.equals(X_val_df.columns), \"Train and validation columns don't match\"\n",
        "assert X_val_df.columns.equals(X_test_df.columns), \"Validation and test columns don't match\"\n",
        "assert X_train_df.isna().sum().sum() == 0, \"NaNs found in X_train_df\"\n",
        "assert X_val_df.isna().sum().sum() == 0, \"NaNs found in X_val_df\"\n",
        "assert X_test_df.isna().sum().sum() == 0, \"NaNs found in X_test_df\"\n",
        "\n",
        "print(f\"Train shape: {X_train_df.shape}\")\n",
        "print(f\"Validation shape: {X_val_df.shape}\")\n",
        "print(f\"Test shape: {X_test_df.shape}\")\n",
        "print(f\"Target distribution (train): {y_train.value_counts().to_dict()}\")\n",
        "print(f\"Target distribution (val): {y_val.value_counts().to_dict()}\")\n",
        "print(f\"Positive class rate (train): {y_train.mean():.4f}\")\n",
        "print(f\"Positive class rate (val): {y_val.mean():.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Business Objective and Revenue Metric\n",
        "\n",
        "**Business Payoff Structure:**\n",
        "- Send voucher to customer who would **NOT reorder** (true class 0): +€1.25 expected uplift\n",
        "- Send voucher to customer who **WOULD reorder anyway** (true class 1): -€5 loss\n",
        "- Do not send voucher: €0 impact\n",
        "\n",
        "**Decision Rule:**\n",
        "- We send a voucher when predicted probability of reorder (P(reorder=1)) is **below** a threshold `t`\n",
        "- Equivalently: send voucher when predicted as \"will NOT reorder\" (class 0)\n",
        "\n",
        "**Why optimize threshold?** The default 0.5 threshold maximizes accuracy but not revenue. Since the cost of sending a voucher to a reorderer (-€5) is much higher than the benefit of sending to a non-reorderer (+€1.25), we need to find the threshold that maximizes expected revenue, not accuracy.\n",
        "\n",
        "**Why use revenue metric over accuracy?** Accuracy treats all misclassifications equally, but in this business context, the costs and benefits are asymmetric. A revenue-based metric directly optimizes for the business objective.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_revenue(y_true, y_pred_proba, threshold):\n",
        "    \"\"\"\n",
        "    Calculate net revenue based on predicted probabilities and threshold.\n",
        "    \n",
        "    Decision rule: send_voucher = 1 if p < threshold else 0\n",
        "    (i.e., send voucher when predicted probability of reorder is LOW)\n",
        "    \n",
        "    Revenue calculation:\n",
        "    - If send_voucher==1 and y_true==0 (would not reorder) => +1.25\n",
        "    - If send_voucher==1 and y_true==1 (would reorder anyway) => -5\n",
        "    - Else (do not send) => 0\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    y_true : array-like\n",
        "        True labels (1 = reorder, 0 = no reorder)\n",
        "    y_pred_proba : array-like\n",
        "        Predicted probabilities of class 1 (reorder)\n",
        "    threshold : float\n",
        "        Threshold for decision (send voucher if p < threshold)\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    total_revenue : float\n",
        "        Total revenue across all customers\n",
        "    avg_revenue : float\n",
        "        Average revenue per customer\n",
        "    send_decisions : array\n",
        "        Binary array indicating send (1) or not send (0)\n",
        "    \"\"\"\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred_proba = np.array(y_pred_proba)\n",
        "    \n",
        "    # Decision: send voucher if probability of reorder is BELOW threshold\n",
        "    send_voucher = (y_pred_proba < threshold).astype(int)\n",
        "    \n",
        "    # Calculate revenue\n",
        "    revenue = np.zeros(len(y_true))\n",
        "    \n",
        "    # Send voucher to non-reorderers: +1.25\n",
        "    revenue[(send_voucher == 1) & (y_true == 0)] = 1.25\n",
        "    \n",
        "    # Send voucher to reorderers: -5\n",
        "    revenue[(send_voucher == 1) & (y_true == 1)] = -5.0\n",
        "    \n",
        "    # Do not send: 0 (already initialized)\n",
        "    \n",
        "    total_revenue = revenue.sum()\n",
        "    avg_revenue = total_revenue / len(y_true)\n",
        "    \n",
        "    return total_revenue, avg_revenue, send_voucher\n",
        "\n",
        "\n",
        "def optimize_threshold(y_true, y_pred_proba, threshold_range=None):\n",
        "    \"\"\"\n",
        "    Find the threshold that maximizes revenue on validation set.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    y_true : array-like\n",
        "        True labels\n",
        "    y_pred_proba : array-like\n",
        "        Predicted probabilities of class 1\n",
        "    threshold_range : array-like, optional\n",
        "        Range of thresholds to search. Default: np.linspace(0.01, 0.99, 99)\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    best_threshold : float\n",
        "        Threshold that maximizes revenue\n",
        "    best_revenue : float\n",
        "        Maximum revenue achieved\n",
        "    results : DataFrame\n",
        "        DataFrame with threshold, revenue pairs\n",
        "    \"\"\"\n",
        "    if threshold_range is None:\n",
        "        threshold_range = np.linspace(0.01, 0.99, 99)\n",
        "    \n",
        "    results = []\n",
        "    \n",
        "    for t in threshold_range:\n",
        "        total_rev, avg_rev, _ = calculate_revenue(y_true, y_pred_proba, t)\n",
        "        results.append({\n",
        "            'threshold': t,\n",
        "            'total_revenue': total_rev,\n",
        "            'avg_revenue': avg_rev\n",
        "        })\n",
        "    \n",
        "    results_df = pd.DataFrame(results)\n",
        "    best_idx = results_df['total_revenue'].idxmax()\n",
        "    best_threshold = results_df.loc[best_idx, 'threshold']\n",
        "    best_revenue = results_df.loc[best_idx, 'total_revenue']\n",
        "    \n",
        "    return best_threshold, best_revenue, results_df\n",
        "\n",
        "\n",
        "# Test the revenue function with a simple example\n",
        "print(\"Revenue function test:\")\n",
        "test_y = np.array([0, 0, 1, 1])\n",
        "test_proba = np.array([0.1, 0.9, 0.1, 0.9])  # Low prob = send voucher\n",
        "test_thresh = 0.5\n",
        "total, avg, decisions = calculate_revenue(test_y, test_proba, test_thresh)\n",
        "print(f\"  Test case: y_true={test_y}, proba={test_proba}, threshold={test_thresh}\")\n",
        "print(f\"  Send decisions: {decisions}\")\n",
        "print(f\"  Total revenue: {total:.2f}, Avg revenue: {avg:.2f}\")\n",
        "print(\"\\nRevenue function validated.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Baseline 1: Always send voucher\n",
        "def baseline_always_send(y_true):\n",
        "    \"\"\"Calculate revenue if we send voucher to everyone.\"\"\"\n",
        "    n = len(y_true)\n",
        "    n_non_reorder = (y_true == 0).sum()\n",
        "    n_reorder = (y_true == 1).sum()\n",
        "    revenue = n_non_reorder * 1.25 + n_reorder * (-5.0)\n",
        "    return revenue, revenue / n\n",
        "\n",
        "\n",
        "# Baseline 2: Never send voucher\n",
        "def baseline_never_send(y_true):\n",
        "    \"\"\"Calculate revenue if we never send voucher.\"\"\"\n",
        "    return 0.0, 0.0\n",
        "\n",
        "\n",
        "# Baseline 3: Random (50% send rate)\n",
        "def baseline_random(y_true, random_state=RANDOM_STATE):\n",
        "    \"\"\"Calculate revenue with random 50% send rate.\"\"\"\n",
        "    np.random.seed(random_state)\n",
        "    n = len(y_true)\n",
        "    send_decisions = np.random.binomial(1, 0.5, n)\n",
        "    revenue = np.zeros(n)\n",
        "    revenue[(send_decisions == 1) & (y_true == 0)] = 1.25\n",
        "    revenue[(send_decisions == 1) & (y_true == 1)] = -5.0\n",
        "    return revenue.sum(), revenue.sum() / n\n",
        "\n",
        "\n",
        "# Calculate baselines on validation set\n",
        "val_baselines = {\n",
        "    'Always Send': baseline_always_send(y_val),\n",
        "    'Never Send': baseline_never_send(y_val),\n",
        "    'Random (50%)': baseline_random(y_val)\n",
        "}\n",
        "\n",
        "print(\"Baseline Performance on Validation Set:\")\n",
        "print(\"=\" * 50)\n",
        "for name, (total, avg) in val_baselines.items():\n",
        "    print(f\"{name:20s}: Total Revenue = €{total:8.2f}, Avg Revenue = €{avg:6.4f}\")\n",
        "print(\"=\" * 50)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Model Training + Tuning\n",
        "\n",
        "Train multiple models and tune hyperparameters using Optuna (for at least one model).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Storage for models and results\n",
        "models = {}\n",
        "results = []\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, title, ax=None):\n",
        "    \"\"\"\n",
        "    Plot confusion matrix using ConfusionMatrixDisplay.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    y_true : array-like\n",
        "        True labels\n",
        "    y_pred : array-like\n",
        "        Predicted labels\n",
        "    title : str\n",
        "        Title for the plot\n",
        "    ax : matplotlib.axes, optional\n",
        "        Axes to plot on. If None, creates new figure.\n",
        "    \"\"\"\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['No Reorder', 'Reorder'])\n",
        "    \n",
        "    if ax is None:\n",
        "        fig, ax = plt.subplots(figsize=(8, 6))\n",
        "    \n",
        "    disp.plot(ax=ax, cmap='Blues', values_format='d')\n",
        "    ax.set_title(title, fontsize=14, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    return ax\n",
        "\n",
        "\n",
        "def evaluate_model(model, model_name, X_train, y_train, X_val, y_val):\n",
        "    \"\"\"\n",
        "    Train a model and evaluate it on validation set using revenue-optimal threshold.\n",
        "    Returns dictionary with all metrics and predictions.\n",
        "    \n",
        "    CRITICAL: All classification metrics (accuracy, precision, recall, F1, confusion matrix)\n",
        "    are computed using y_pred_optimal = (y_pred_proba < best_threshold), which is the\n",
        "    revenue-optimal decision rule, NOT the default model.predict().\n",
        "    \"\"\"\n",
        "    # Train\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    # Probabilities (handle models without predict_proba)\n",
        "    if hasattr(model, 'predict_proba'):\n",
        "        y_pred_proba = model.predict_proba(X_val)[:, 1]\n",
        "    elif hasattr(model, 'decision_function'):\n",
        "        # For SVM-like models, use decision function and sigmoid\n",
        "        decision = model.decision_function(X_val)\n",
        "        y_pred_proba = 1 / (1 + np.exp(-decision))  # Sigmoid\n",
        "    else:\n",
        "        # Fallback: use predict and convert to probabilities\n",
        "        y_pred = model.predict(X_val)\n",
        "        y_pred_proba = y_pred.astype(float)\n",
        "    \n",
        "    # Ensure probabilities are in [0, 1]\n",
        "    y_pred_proba = np.clip(y_pred_proba, 0, 1)\n",
        "    \n",
        "    # Assert probabilities are valid\n",
        "    assert np.all((y_pred_proba >= 0) & (y_pred_proba <= 1)), f\"Invalid probabilities for {model_name}\"\n",
        "    \n",
        "    # Threshold optimization for revenue\n",
        "    best_threshold, best_revenue, threshold_results = optimize_threshold(y_val, y_pred_proba)\n",
        "    \n",
        "    # Revenue-optimal decision: send voucher if p < threshold\n",
        "    y_pred_optimal = (y_pred_proba < best_threshold).astype(int)\n",
        "    \n",
        "    # Standard metrics computed on revenue-optimal decisions\n",
        "    accuracy = accuracy_score(y_val, y_pred_optimal)\n",
        "    precision = precision_score(y_val, y_pred_optimal, zero_division=0)\n",
        "    recall = recall_score(y_val, y_pred_optimal, zero_division=0)\n",
        "    f1 = f1_score(y_val, y_pred_optimal, zero_division=0)\n",
        "    \n",
        "    # ROC-AUC computed on probabilities (not thresholded)\n",
        "    try:\n",
        "        roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
        "    except:\n",
        "        roc_auc = np.nan\n",
        "    \n",
        "    # Confusion matrix using revenue-optimal decisions\n",
        "    cm_optimal = confusion_matrix(y_val, y_pred_optimal)\n",
        "    \n",
        "    # Classification report text\n",
        "    report_text = classification_report(y_val, y_pred_optimal, target_names=['No Reorder', 'Reorder'])\n",
        "    \n",
        "    # Revenue at optimal threshold\n",
        "    total_revenue, avg_revenue, _ = calculate_revenue(y_val, y_pred_proba, best_threshold)\n",
        "    \n",
        "    result = {\n",
        "        'model_name': model_name,\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1,\n",
        "        'roc_auc': roc_auc,\n",
        "        'best_threshold': best_threshold,\n",
        "        'total_revenue': total_revenue,\n",
        "        'avg_revenue': avg_revenue,\n",
        "        'confusion_matrix': cm_optimal,  # Using revenue-optimal decisions\n",
        "        'y_pred_proba': y_pred_proba,\n",
        "        'y_pred_optimal': y_pred_optimal,  # Revenue-optimal binary predictions\n",
        "        'threshold_results': threshold_results,\n",
        "        'classification_report': report_text\n",
        "    }\n",
        "    \n",
        "    return result, model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.1 Logistic Regression (Baseline)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Training Logistic Regression...\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Light tuning for Logistic Regression\n",
        "print(\"Performing light hyperparameter tuning...\")\n",
        "lr_param_grid = {\n",
        "    'C': np.logspace(-3, 2, 6),\n",
        "    'penalty': ['l2'],\n",
        "    'solver': ['lbfgs', 'liblinear']\n",
        "}\n",
        "lr_base = LogisticRegression(random_state=RANDOM_STATE, max_iter=1000, class_weight='balanced')\n",
        "lr_search = RandomizedSearchCV(\n",
        "    lr_base, lr_param_grid, n_iter=12, cv=3, scoring='roc_auc',\n",
        "    random_state=RANDOM_STATE, n_jobs=-1, verbose=0\n",
        ")\n",
        "lr_search.fit(X_train_df, y_train)\n",
        "lr = lr_search.best_estimator_\n",
        "print(f\"Best parameters: {lr_search.best_params_}\")\n",
        "\n",
        "result_lr, model_lr = evaluate_model(lr, 'Logistic Regression', X_train_df, y_train, X_val_df, y_val)\n",
        "models['Logistic Regression'] = model_lr\n",
        "results.append(result_lr)\n",
        "\n",
        "print(f\"\\nValidation Metrics (at threshold={result_lr['best_threshold']:.4f}):\")\n",
        "print(f\"  Accuracy: {result_lr['accuracy']:.4f}\")\n",
        "print(f\"  Precision: {result_lr['precision']:.4f}\")\n",
        "print(f\"  Recall: {result_lr['recall']:.4f}\")\n",
        "print(f\"  F1: {result_lr['f1']:.4f}\")\n",
        "print(f\"  ROC-AUC: {result_lr['roc_auc']:.4f}\")\n",
        "print(f\"  Total Revenue: €{result_lr['total_revenue']:.2f}\")\n",
        "print(f\"  Avg Revenue: €{result_lr['avg_revenue']:.4f}\")\n",
        "\n",
        "# Confusion matrix plot\n",
        "plot_confusion_matrix(\n",
        "    y_val, result_lr['y_pred_optimal'],\n",
        "    f\"Logistic Regression (threshold={result_lr['best_threshold']:.4f})\"\n",
        ")\n",
        "plt.show()\n",
        "\n",
        "# Classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(result_lr['classification_report'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Training Random Forest...\")\n",
        "print(\"=\" * 80)\n",
        "rf = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=10,\n",
        "    min_samples_split=5,\n",
        "    min_samples_leaf=2,\n",
        "    class_weight='balanced',\n",
        "    random_state=RANDOM_STATE,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "result_rf, model_rf = evaluate_model(rf, 'Random Forest', X_train_df, y_train, X_val_df, y_val)\n",
        "models['Random Forest'] = model_rf\n",
        "results.append(result_rf)\n",
        "\n",
        "print(f\"\\nValidation Metrics (at threshold={result_rf['best_threshold']:.4f}):\")\n",
        "print(f\"  Accuracy: {result_rf['accuracy']:.4f}\")\n",
        "print(f\"  Precision: {result_rf['precision']:.4f}\")\n",
        "print(f\"  Recall: {result_rf['recall']:.4f}\")\n",
        "print(f\"  F1: {result_rf['f1']:.4f}\")\n",
        "print(f\"  ROC-AUC: {result_rf['roc_auc']:.4f}\")\n",
        "print(f\"  Total Revenue: €{result_rf['total_revenue']:.2f}\")\n",
        "print(f\"  Avg Revenue: €{result_rf['avg_revenue']:.4f}\")\n",
        "\n",
        "# Confusion matrix plot\n",
        "plot_confusion_matrix(\n",
        "    y_val, result_rf['y_pred_optimal'],\n",
        "    f\"Random Forest (threshold={result_rf['best_threshold']:.4f})\"\n",
        ")\n",
        "plt.show()\n",
        "\n",
        "# Classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(result_rf['classification_report'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.3 Gradient Boosting\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Training Gradient Boosting...\")\n",
        "print(\"=\" * 80)\n",
        "gb = GradientBoostingClassifier(\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=5,\n",
        "    min_samples_split=5,\n",
        "    min_samples_leaf=2,\n",
        "    random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "result_gb, model_gb = evaluate_model(gb, 'Gradient Boosting', X_train_df, y_train, X_val_df, y_val)\n",
        "models['Gradient Boosting'] = model_gb\n",
        "results.append(result_gb)\n",
        "\n",
        "print(f\"\\nValidation Metrics (at threshold={result_gb['best_threshold']:.4f}):\")\n",
        "print(f\"  Accuracy: {result_gb['accuracy']:.4f}\")\n",
        "print(f\"  Precision: {result_gb['precision']:.4f}\")\n",
        "print(f\"  Recall: {result_gb['recall']:.4f}\")\n",
        "print(f\"  F1: {result_gb['f1']:.4f}\")\n",
        "print(f\"  ROC-AUC: {result_gb['roc_auc']:.4f}\")\n",
        "print(f\"  Total Revenue: €{result_gb['total_revenue']:.2f}\")\n",
        "print(f\"  Avg Revenue: €{result_gb['avg_revenue']:.4f}\")\n",
        "\n",
        "# Confusion matrix plot\n",
        "plot_confusion_matrix(\n",
        "    y_val, result_gb['y_pred_optimal'],\n",
        "    f\"Gradient Boosting (threshold={result_gb['best_threshold']:.4f})\"\n",
        ")\n",
        "plt.show()\n",
        "\n",
        "# Classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(result_gb['classification_report'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.4 AdaBoost\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Training AdaBoost...\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Light tuning for AdaBoost\n",
        "print(\"Performing light hyperparameter tuning...\")\n",
        "ada_param_grid = {\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'learning_rate': [0.5, 1.0, 1.5]\n",
        "}\n",
        "ada_base = AdaBoostClassifier(random_state=RANDOM_STATE)\n",
        "ada_search = RandomizedSearchCV(\n",
        "    ada_base, ada_param_grid, n_iter=9, cv=3, scoring='roc_auc',\n",
        "    random_state=RANDOM_STATE, n_jobs=-1, verbose=0\n",
        ")\n",
        "ada_search.fit(X_train_df, y_train)\n",
        "ada = ada_search.best_estimator_\n",
        "print(f\"Best parameters: {ada_search.best_params_}\")\n",
        "\n",
        "result_ada, model_ada = evaluate_model(ada, 'AdaBoost', X_train_df, y_train, X_val_df, y_val)\n",
        "models['AdaBoost'] = model_ada\n",
        "results.append(result_ada)\n",
        "\n",
        "print(f\"\\nValidation Metrics (at threshold={result_ada['best_threshold']:.4f}):\")\n",
        "print(f\"  Accuracy: {result_ada['accuracy']:.4f}\")\n",
        "print(f\"  Precision: {result_ada['precision']:.4f}\")\n",
        "print(f\"  Recall: {result_ada['recall']:.4f}\")\n",
        "print(f\"  F1: {result_ada['f1']:.4f}\")\n",
        "print(f\"  ROC-AUC: {result_ada['roc_auc']:.4f}\")\n",
        "print(f\"  Total Revenue: €{result_ada['total_revenue']:.2f}\")\n",
        "print(f\"  Avg Revenue: €{result_ada['avg_revenue']:.4f}\")\n",
        "\n",
        "# Confusion matrix plot\n",
        "plot_confusion_matrix(\n",
        "    y_val, result_ada['y_pred_optimal'],\n",
        "    f\"AdaBoost (threshold={result_ada['best_threshold']:.4f})\"\n",
        ")\n",
        "plt.show()\n",
        "\n",
        "# Classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(result_ada['classification_report'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.5 K-Nearest Neighbors (with scaling)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Training K-Nearest Neighbors (with StandardScaler)...\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Light tuning for KNN\n",
        "print(\"Performing light hyperparameter tuning...\")\n",
        "knn_param_grid = {\n",
        "    'knn__n_neighbors': [3, 5, 7, 9, 11],\n",
        "    'knn__weights': ['uniform', 'distance'],\n",
        "    'knn__p': [1, 2]\n",
        "}\n",
        "knn_base = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('knn', KNeighborsClassifier())\n",
        "])\n",
        "knn_search = RandomizedSearchCV(\n",
        "    knn_base, knn_param_grid, n_iter=20, cv=3, scoring='roc_auc',\n",
        "    random_state=RANDOM_STATE, n_jobs=-1, verbose=0\n",
        ")\n",
        "knn_search.fit(X_train_df, y_train)\n",
        "knn_pipeline = knn_search.best_estimator_\n",
        "print(f\"Best parameters: {knn_search.best_params_}\")\n",
        "\n",
        "result_knn, model_knn = evaluate_model(knn_pipeline, 'KNN', X_train_df, y_train, X_val_df, y_val)\n",
        "models['KNN'] = model_knn\n",
        "results.append(result_knn)\n",
        "\n",
        "print(f\"\\nValidation Metrics (at threshold={result_knn['best_threshold']:.4f}):\")\n",
        "print(f\"  Accuracy: {result_knn['accuracy']:.4f}\")\n",
        "print(f\"  Precision: {result_knn['precision']:.4f}\")\n",
        "print(f\"  Recall: {result_knn['recall']:.4f}\")\n",
        "print(f\"  F1: {result_knn['f1']:.4f}\")\n",
        "print(f\"  ROC-AUC: {result_knn['roc_auc']:.4f}\")\n",
        "print(f\"  Total Revenue: €{result_knn['total_revenue']:.2f}\")\n",
        "print(f\"  Avg Revenue: €{result_knn['avg_revenue']:.4f}\")\n",
        "\n",
        "# Confusion matrix plot\n",
        "plot_confusion_matrix(\n",
        "    y_val, result_knn['y_pred_optimal'],\n",
        "    f\"KNN (threshold={result_knn['best_threshold']:.4f})\"\n",
        ")\n",
        "plt.show()\n",
        "\n",
        "# Classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(result_knn['classification_report'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.6 XGBoost or HistGradientBoosting\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if XGBOOST_AVAILABLE:\n",
        "    print(\"Training XGBoost...\")\n",
        "    print(\"=\" * 80)\n",
        "    xgb_model = xgb.XGBClassifier(\n",
        "        n_estimators=100,\n",
        "        learning_rate=0.1,\n",
        "        max_depth=5,\n",
        "        min_child_weight=1,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        random_state=RANDOM_STATE,\n",
        "        n_jobs=-1,\n",
        "        eval_metric='logloss'\n",
        "    )\n",
        "    \n",
        "    result_xgb, model_xgb = evaluate_model(xgb_model, 'XGBoost', X_train_df, y_train, X_val_df, y_val)\n",
        "    models['XGBoost'] = model_xgb\n",
        "    results.append(result_xgb)\n",
        "    \n",
        "    print(f\"\\nValidation Metrics (at threshold={result_xgb['best_threshold']:.4f}):\")\n",
        "    print(f\"  Accuracy: {result_xgb['accuracy']:.4f}\")\n",
        "    print(f\"  Precision: {result_xgb['precision']:.4f}\")\n",
        "    print(f\"  Recall: {result_xgb['recall']:.4f}\")\n",
        "    print(f\"  F1: {result_xgb['f1']:.4f}\")\n",
        "    print(f\"  ROC-AUC: {result_xgb['roc_auc']:.4f}\")\n",
        "    print(f\"  Total Revenue: €{result_xgb['total_revenue']:.2f}\")\n",
        "    print(f\"  Avg Revenue: €{result_xgb['avg_revenue']:.4f}\")\n",
        "    \n",
        "    # Confusion matrix plot\n",
        "    plot_confusion_matrix(\n",
        "        y_val, result_xgb['y_pred_optimal'],\n",
        "        f\"XGBoost (threshold={result_xgb['best_threshold']:.4f})\"\n",
        "    )\n",
        "    plt.show()\n",
        "    \n",
        "    # Classification report\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(result_xgb['classification_report'])\n",
        "else:\n",
        "    print(\"Training HistGradientBoostingClassifier (XGBoost fallback)...\")\n",
        "    print(\"=\" * 80)\n",
        "    hgb = HistGradientBoostingClassifier(\n",
        "        max_iter=100,\n",
        "        learning_rate=0.1,\n",
        "        max_depth=5,\n",
        "        random_state=RANDOM_STATE\n",
        "    )\n",
        "    \n",
        "    result_hgb, model_hgb = evaluate_model(hgb, 'HistGradientBoosting', X_train_df, y_train, X_val_df, y_val)\n",
        "    models['HistGradientBoosting'] = model_hgb\n",
        "    results.append(result_hgb)\n",
        "    \n",
        "    print(f\"\\nValidation Metrics (at threshold={result_hgb['best_threshold']:.4f}):\")\n",
        "    print(f\"  Accuracy: {result_hgb['accuracy']:.4f}\")\n",
        "    print(f\"  Precision: {result_hgb['precision']:.4f}\")\n",
        "    print(f\"  Recall: {result_hgb['recall']:.4f}\")\n",
        "    print(f\"  F1: {result_hgb['f1']:.4f}\")\n",
        "    print(f\"  ROC-AUC: {result_hgb['roc_auc']:.4f}\")\n",
        "    print(f\"  Total Revenue: €{result_hgb['total_revenue']:.2f}\")\n",
        "    print(f\"  Avg Revenue: €{result_hgb['avg_revenue']:.4f}\")\n",
        "    \n",
        "    # Confusion matrix plot\n",
        "    plot_confusion_matrix(\n",
        "        y_val, result_hgb['y_pred_optimal'],\n",
        "        f\"HistGradientBoosting (threshold={result_hgb['best_threshold']:.4f})\"\n",
        "    )\n",
        "    plt.show()\n",
        "    \n",
        "    # Classification report\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(result_hgb['classification_report'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.7 Hyperparameter Tuning with Optuna\n",
        "\n",
        "Tune hyperparameters for a strong model (XGBoost or Random Forest) using Optuna, optimizing for **validation revenue**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if OPTUNA_AVAILABLE:\n",
        "    print(\"Setting up Optuna hyperparameter tuning...\")\n",
        "    \n",
        "    # Choose model to tune (prefer XGBoost if available, else Random Forest)\n",
        "    if XGBOOST_AVAILABLE:\n",
        "        model_to_tune = 'XGBoost'\n",
        "        \n",
        "        def objective_xgb(trial):\n",
        "            \"\"\"Optuna objective for XGBoost, maximizing validation revenue.\"\"\"\n",
        "            params = {\n",
        "                'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
        "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
        "                'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
        "                'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
        "                'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
        "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
        "                'random_state': RANDOM_STATE,\n",
        "                'n_jobs': -1,\n",
        "                'eval_metric': 'logloss'\n",
        "            }\n",
        "            \n",
        "            model = xgb.XGBClassifier(**params)\n",
        "            model.fit(X_train_df, y_train)\n",
        "            \n",
        "            # Get probabilities\n",
        "            y_pred_proba = model.predict_proba(X_val_df)[:, 1]\n",
        "            \n",
        "            # Optimize threshold to maximize revenue\n",
        "            best_threshold, best_revenue, _ = optimize_threshold(y_val, y_pred_proba)\n",
        "            \n",
        "            return best_revenue  # Optuna maximizes, so return revenue directly\n",
        "        \n",
        "        study = optuna.create_study(\n",
        "            direction='maximize',\n",
        "            sampler=optuna.samplers.TPESampler(seed=RANDOM_STATE)\n",
        "        )\n",
        "        \n",
        "        print(f\"Running Optuna optimization for {model_to_tune} (maximizing validation revenue)...\")\n",
        "        print(\"This may take several minutes...\")\n",
        "        \n",
        "        study.optimize(objective_xgb, n_trials=60, show_progress_bar=True)\n",
        "        \n",
        "        print(f\"\\nBest trial revenue: €{study.best_value:.2f}\")\n",
        "        print(f\"Best parameters: {study.best_params}\")\n",
        "        \n",
        "        # Train final model with best parameters\n",
        "        best_params = study.best_params.copy()\n",
        "        best_params['random_state'] = RANDOM_STATE\n",
        "        best_params['n_jobs'] = -1\n",
        "        best_params['eval_metric'] = 'logloss'\n",
        "        \n",
        "        xgb_tuned = xgb.XGBClassifier(**best_params)\n",
        "        result_xgb_tuned, model_xgb_tuned = evaluate_model(\n",
        "            xgb_tuned, 'XGBoost (Optuna Tuned)', X_train_df, y_train, X_val_df, y_val\n",
        "        )\n",
        "        models['XGBoost (Optuna Tuned)'] = model_xgb_tuned\n",
        "        results.append(result_xgb_tuned)\n",
        "        \n",
        "        print(f\"\\nTuned Model Performance:\")\n",
        "        print(f\"  Accuracy: {result_xgb_tuned['accuracy']:.4f}\")\n",
        "        print(f\"  Precision: {result_xgb_tuned['precision']:.4f}\")\n",
        "        print(f\"  Recall: {result_xgb_tuned['recall']:.4f}\")\n",
        "        print(f\"  F1: {result_xgb_tuned['f1']:.4f}\")\n",
        "        print(f\"  ROC-AUC: {result_xgb_tuned['roc_auc']:.4f}\")\n",
        "        print(f\"  Best Threshold: {result_xgb_tuned['best_threshold']:.4f}\")\n",
        "        print(f\"  Total Revenue: €{result_xgb_tuned['total_revenue']:.2f}\")\n",
        "        print(f\"  Avg Revenue: €{result_xgb_tuned['avg_revenue']:.4f}\")\n",
        "        \n",
        "        # Confusion matrix plot\n",
        "        plot_confusion_matrix(\n",
        "            y_val, result_xgb_tuned['y_pred_optimal'],\n",
        "            f\"XGBoost (Optuna Tuned, threshold={result_xgb_tuned['best_threshold']:.4f})\"\n",
        "        )\n",
        "        plt.show()\n",
        "        \n",
        "        # Classification report\n",
        "        print(\"\\nClassification Report:\")\n",
        "        print(result_xgb_tuned['classification_report'])\n",
        "        \n",
        "    else:\n",
        "        # Tune Random Forest\n",
        "        model_to_tune = 'Random Forest'\n",
        "        \n",
        "        def objective_rf(trial):\n",
        "            \"\"\"Optuna objective for Random Forest, maximizing validation revenue.\"\"\"\n",
        "            params = {\n",
        "                'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
        "                'max_depth': trial.suggest_int('max_depth', 5, 20),\n",
        "                'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
        "                'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
        "                'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2', None]),\n",
        "                'class_weight': 'balanced',\n",
        "                'random_state': RANDOM_STATE,\n",
        "                'n_jobs': -1\n",
        "            }\n",
        "            \n",
        "            model = RandomForestClassifier(**params)\n",
        "            model.fit(X_train_df, y_train)\n",
        "            \n",
        "            y_pred_proba = model.predict_proba(X_val_df)[:, 1]\n",
        "            best_threshold, best_revenue, _ = optimize_threshold(y_val, y_pred_proba)\n",
        "            \n",
        "            return best_revenue\n",
        "        \n",
        "        study = optuna.create_study(\n",
        "            direction='maximize',\n",
        "            sampler=optuna.samplers.TPESampler(seed=RANDOM_STATE)\n",
        "        )\n",
        "        \n",
        "        print(f\"Running Optuna optimization for {model_to_tune} (maximizing validation revenue)...\")\n",
        "        print(\"This may take several minutes...\")\n",
        "        \n",
        "        study.optimize(objective_rf, n_trials=60, show_progress_bar=True)\n",
        "        \n",
        "        print(f\"\\nBest trial revenue: €{study.best_value:.2f}\")\n",
        "        print(f\"Best parameters: {study.best_params}\")\n",
        "        \n",
        "        # Train final model\n",
        "        best_params = study.best_params.copy()\n",
        "        best_params['random_state'] = RANDOM_STATE\n",
        "        best_params['n_jobs'] = -1\n",
        "        \n",
        "        rf_tuned = RandomForestClassifier(**best_params)\n",
        "        result_rf_tuned, model_rf_tuned = evaluate_model(\n",
        "            rf_tuned, 'Random Forest (Optuna Tuned)', X_train_df, y_train, X_val_df, y_val\n",
        "        )\n",
        "        models['Random Forest (Optuna Tuned)'] = model_rf_tuned\n",
        "        results.append(result_rf_tuned)\n",
        "        \n",
        "        print(f\"\\nTuned Model Performance:\")\n",
        "        print(f\"  Accuracy: {result_rf_tuned['accuracy']:.4f}\")\n",
        "        print(f\"  Precision: {result_rf_tuned['precision']:.4f}\")\n",
        "        print(f\"  Recall: {result_rf_tuned['recall']:.4f}\")\n",
        "        print(f\"  F1: {result_rf_tuned['f1']:.4f}\")\n",
        "        print(f\"  ROC-AUC: {result_rf_tuned['roc_auc']:.4f}\")\n",
        "        print(f\"  Best Threshold: {result_rf_tuned['best_threshold']:.4f}\")\n",
        "        print(f\"  Total Revenue: €{result_rf_tuned['total_revenue']:.2f}\")\n",
        "        print(f\"  Avg Revenue: €{result_rf_tuned['avg_revenue']:.4f}\")\n",
        "        \n",
        "        # Confusion matrix plot\n",
        "        plot_confusion_matrix(\n",
        "            y_val, result_rf_tuned['y_pred_optimal'],\n",
        "            f\"Random Forest (Optuna Tuned, threshold={result_rf_tuned['best_threshold']:.4f})\"\n",
        "        )\n",
        "        plt.show()\n",
        "        \n",
        "        # Classification report\n",
        "        print(\"\\nClassification Report:\")\n",
        "        print(result_rf_tuned['classification_report'])\n",
        "else:\n",
        "    print(\"Optuna not available. Skipping hyperparameter tuning.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Threshold Optimization\n",
        "\n",
        "Threshold optimization is performed during model evaluation. We search over a range of thresholds to find the one that maximizes validation revenue, since the default 0.5 threshold is unlikely to be optimal for our asymmetric cost structure. Here we visualize the threshold-revenue relationship for the best model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find best model by revenue\n",
        "best_model_result = max(results, key=lambda x: x['total_revenue'])\n",
        "best_model_name = best_model_result['model_name']\n",
        "\n",
        "print(f\"Best model by revenue: {best_model_name}\")\n",
        "print(f\"Best threshold: {best_model_result['best_threshold']:.4f}\")\n",
        "print(f\"Total revenue: €{best_model_result['total_revenue']:.2f}\")\n",
        "print(f\"Average revenue: €{best_model_result['avg_revenue']:.4f}\")\n",
        "\n",
        "# Plot threshold-revenue curve for best model\n",
        "threshold_df = best_model_result['threshold_results']\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(threshold_df['threshold'], threshold_df['total_revenue'], 'b-', linewidth=2)\n",
        "plt.axvline(best_model_result['best_threshold'], color='r', linestyle='--', \n",
        "            label=f'Optimal threshold = {best_model_result[\"best_threshold\"]:.4f}')\n",
        "plt.xlabel('Threshold (send voucher if p < threshold)')\n",
        "plt.ylabel('Total Revenue (€)')\n",
        "plt.title(f'Revenue vs Threshold: {best_model_name}')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Model Comparison Table\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comparison DataFrame\n",
        "comparison_data = []\n",
        "for r in results:\n",
        "    comparison_data.append({\n",
        "        'Model': r['model_name'],\n",
        "        'Accuracy': r['accuracy'],\n",
        "        'Precision': r['precision'],\n",
        "        'Recall': r['recall'],\n",
        "        'F1': r['f1'],\n",
        "        'ROC-AUC': r['roc_auc'],\n",
        "        'Best Threshold': r['best_threshold'],\n",
        "        'Total Revenue (€)': r['total_revenue'],\n",
        "        'Avg Revenue (€)': r['avg_revenue']\n",
        "    })\n",
        "\n",
        "comparison_df = pd.DataFrame(comparison_data)\n",
        "comparison_df = comparison_df.sort_values('Total Revenue (€)', ascending=False)\n",
        "\n",
        "print(\"Model Comparison (sorted by Total Revenue):\")\n",
        "print(\"=\" * 100)\n",
        "print(comparison_df.to_string(index=False))\n",
        "print(\"=\" * 100)\n",
        "\n",
        "# Save comparison table\n",
        "comparison_df.to_csv('model_comparison.csv', index=False)\n",
        "print(\"\\nComparison table saved to 'model_comparison.csv'\")\n",
        "\n",
        "# Model comparison bar chart: Total Revenue by Model\n",
        "plt.figure(figsize=(12, 6))\n",
        "colors = plt.cm.viridis(np.linspace(0, 1, len(comparison_df)))\n",
        "bars = plt.barh(comparison_df['Model'], comparison_df['Total Revenue (€)'], color=colors)\n",
        "plt.xlabel('Total Revenue (€)', fontsize=12)\n",
        "plt.ylabel('Model', fontsize=12)\n",
        "plt.title('Model Comparison: Total Validation Revenue', fontsize=14, fontweight='bold')\n",
        "plt.grid(axis='x', alpha=0.3)\n",
        "\n",
        "# Add value labels on bars\n",
        "for i, (bar, value) in enumerate(zip(bars, comparison_df['Total Revenue (€)'])):\n",
        "    plt.text(value + max(comparison_df['Total Revenue (€)']) * 0.01, bar.get_y() + bar.get_height()/2,\n",
        "             f'€{value:.2f}', va='center', fontsize=9)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calibration curves for top 2 models\n",
        "print(\"\\nCalibration Curves (Top 2 Models by Revenue):\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "top_2_models = comparison_df.head(2)['Model'].tolist()\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "for idx, model_name in enumerate(top_2_models):\n",
        "    # Find the result for this model\n",
        "    model_result = next(r for r in results if r['model_name'] == model_name)\n",
        "    y_pred_proba = model_result['y_pred_proba']\n",
        "    \n",
        "    # Compute calibration curve\n",
        "    fraction_of_positives, mean_predicted_value = calibration_curve(\n",
        "        y_val, y_pred_proba, n_bins=10, strategy='uniform'\n",
        "    )\n",
        "    \n",
        "    ax = axes[idx]\n",
        "    ax.plot(mean_predicted_value, fraction_of_positives, \"s-\", label=model_name)\n",
        "    ax.plot([0, 1], [0, 1], \"k--\", label=\"Perfectly calibrated\")\n",
        "    ax.set_xlabel('Mean Predicted Probability', fontsize=11)\n",
        "    ax.set_ylabel('Fraction of Positives', fontsize=11)\n",
        "    ax.set_title(f'Calibration Curve: {model_name}', fontsize=12, fontweight='bold')\n",
        "    ax.legend()\n",
        "    ax.grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nNote: Calibration curves show how well predicted probabilities match actual frequencies.\")\n",
        "print(\"A well-calibrated model should lie close to the diagonal line.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Final Model Selection\n",
        "\n",
        "Select the best model based on validation revenue.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Select best model\n",
        "best_model_name = best_model_result['model_name']\n",
        "best_model = models[best_model_name]\n",
        "best_threshold = best_model_result['best_threshold']\n",
        "\n",
        "print(f\"Selected Best Model: {best_model_name}\")\n",
        "print(f\"Optimal Threshold: {best_threshold:.4f}\")\n",
        "print(f\"Validation Total Revenue: €{best_model_result['total_revenue']:.2f}\")\n",
        "print(f\"Validation Average Revenue: €{best_model_result['avg_revenue']:.4f}\")\n",
        "print(f\"Validation Accuracy: {best_model_result['accuracy']:.4f}\")\n",
        "print(f\"Validation ROC-AUC: {best_model_result['roc_auc']:.4f}\")\n",
        "\n",
        "# Print voucher send-rate on validation\n",
        "val_send_rate = best_model_result['y_pred_optimal'].mean()\n",
        "print(f\"\\nVoucher Send-Rate on Validation: {val_send_rate*100:.2f}%\")\n",
        "print(f\"  ({best_model_result['y_pred_optimal'].sum()} vouchers sent out of {len(best_model_result['y_pred_optimal'])} customers)\")\n",
        "\n",
        "# Save best model and threshold\n",
        "joblib.dump(best_model, 'best_model.joblib')\n",
        "print(\"\\nBest model saved to 'best_model.joblib'\")\n",
        "\n",
        "with open('best_threshold.json', 'w') as f:\n",
        "    json.dump({'threshold': float(best_threshold), 'model_name': best_model_name}, f, indent=2)\n",
        "print(\"Best threshold saved to 'best_threshold.json'\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Predict on Unlabeled Test Set and Export Submission\n",
        "\n",
        "Train the final model on the full labeled data (train + validation) and generate predictions for the test set. The test set (test.csv) is unlabeled, so we cannot compute out-of-sample metrics. All evaluation and model selection must be based on the validation set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Combine train and validation for final training\n",
        "X_full = pd.concat([X_train_df, X_val_df], axis=0)\n",
        "y_full = pd.concat([y_train, y_val], axis=0)\n",
        "\n",
        "print(f\"Full training set shape: {X_full.shape}\")\n",
        "print(f\"Full training target distribution: {y_full.value_counts().to_dict()}\")\n",
        "\n",
        "# Retrain best model on full data\n",
        "print(f\"\\nRetraining {best_model_name} on full labeled data...\")\n",
        "\n",
        "# Get the model class and parameters\n",
        "if 'XGBoost' in best_model_name:\n",
        "    if hasattr(best_model, 'get_params'):\n",
        "        final_model = xgb.XGBClassifier(**best_model.get_params())\n",
        "    else:\n",
        "        # Fallback: use default parameters\n",
        "        final_model = xgb.XGBClassifier(random_state=RANDOM_STATE, n_jobs=-1)\n",
        "elif 'Random Forest' in best_model_name:\n",
        "    if hasattr(best_model, 'get_params'):\n",
        "        final_model = RandomForestClassifier(**best_model.get_params())\n",
        "    else:\n",
        "        final_model = RandomForestClassifier(random_state=RANDOM_STATE, n_jobs=-1)\n",
        "elif 'Gradient Boosting' in best_model_name:\n",
        "    if hasattr(best_model, 'get_params'):\n",
        "        final_model = GradientBoostingClassifier(**best_model.get_params())\n",
        "    else:\n",
        "        final_model = GradientBoostingClassifier(random_state=RANDOM_STATE)\n",
        "elif 'AdaBoost' in best_model_name:\n",
        "    if hasattr(best_model, 'get_params'):\n",
        "        final_model = AdaBoostClassifier(**best_model.get_params())\n",
        "    else:\n",
        "        final_model = AdaBoostClassifier(random_state=RANDOM_STATE)\n",
        "elif 'KNN' in best_model_name:\n",
        "    if hasattr(best_model, 'get_params'):\n",
        "        # Clone the pipeline to preserve tuned parameters\n",
        "        from sklearn.base import clone\n",
        "        final_model = clone(best_model)\n",
        "    else:\n",
        "        final_model = Pipeline([\n",
        "            ('scaler', StandardScaler()),\n",
        "            ('knn', KNeighborsClassifier(n_neighbors=5, weights='distance'))\n",
        "        ])\n",
        "elif 'Logistic' in best_model_name:\n",
        "    if hasattr(best_model, 'get_params'):\n",
        "        final_model = LogisticRegression(**best_model.get_params())\n",
        "    else:\n",
        "        final_model = LogisticRegression(random_state=RANDOM_STATE, max_iter=1000)\n",
        "elif 'HistGradientBoosting' in best_model_name:\n",
        "    if hasattr(best_model, 'get_params'):\n",
        "        final_model = HistGradientBoostingClassifier(**best_model.get_params())\n",
        "    else:\n",
        "        final_model = HistGradientBoostingClassifier(random_state=RANDOM_STATE)\n",
        "else:\n",
        "    # Generic fallback: clone the model\n",
        "    from sklearn.base import clone\n",
        "    final_model = clone(best_model)\n",
        "\n",
        "final_model.fit(X_full, y_full)\n",
        "print(\"Model retrained on full data.\")\n",
        "\n",
        "# Predict on test set\n",
        "print(\"\\nGenerating predictions on test set...\")\n",
        "p_test = final_model.predict_proba(X_test_df)[:, 1]\n",
        "\n",
        "# Ensure probabilities are valid\n",
        "assert np.all((p_test >= 0) & (p_test <= 1)), \"Invalid probabilities detected\"\n",
        "\n",
        "# Apply decision rule: send_voucher = 1 if p < threshold\n",
        "voucher_decision = (p_test < best_threshold).astype(int)\n",
        "\n",
        "print(f\"Test set predictions generated.\")\n",
        "print(f\"Number of vouchers to send: {voucher_decision.sum()} out of {len(voucher_decision)} ({voucher_decision.mean()*100:.2f}%)\")\n",
        "\n",
        "# Quality checks\n",
        "print(\"\\nQuality Checks:\")\n",
        "print(f\"  Probabilities in valid range [0,1]: {np.all((p_test >= 0) & (p_test <= 1))}\")\n",
        "print(f\"  Voucher decisions are binary: {set(voucher_decision) <= {0, 1}}\")\n",
        "print(f\"  Test set voucher send-rate: {voucher_decision.mean()*100:.2f}%\")\n",
        "\n",
        "# Create submission DataFrame\n",
        "# Note: If customernumber is not available in test, we'll use index\n",
        "try:\n",
        "    # Try to load test.csv to get customernumber if available\n",
        "    test_raw = pd.read_csv('test.csv', sep=';', low_memory=False)\n",
        "    if 'customernumber' in test_raw.columns:\n",
        "        submission = pd.DataFrame({\n",
        "            'customernumber': test_raw['customernumber'].values,\n",
        "            'voucher_decision': voucher_decision\n",
        "        })\n",
        "    else:\n",
        "        submission = pd.DataFrame({\n",
        "            'customernumber': X_test_df.index,\n",
        "            'voucher_decision': voucher_decision\n",
        "        })\n",
        "except:\n",
        "    submission = pd.DataFrame({\n",
        "        'customernumber': X_test_df.index,\n",
        "        'voucher_decision': voucher_decision\n",
        "    })\n",
        "\n",
        "# Export submission\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "print(f\"\\nSubmission file saved to 'submission.csv'\")\n",
        "print(f\"Submission shape: {submission.shape}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "print(submission.head(10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Interpretability Hooks\n",
        "\n",
        "Extract feature importances and coefficients for model interpretation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature importances for tree-based models\n",
        "print(\"Feature Importances (Tree-based Models):\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    if hasattr(model, 'feature_importances_'):\n",
        "        importances = model.feature_importances_\n",
        "        feature_imp_df = pd.DataFrame({\n",
        "            'feature': X_train_df.columns,\n",
        "            'importance': importances\n",
        "        }).sort_values('importance', ascending=False)\n",
        "        \n",
        "        print(f\"\\n{model_name} - Top 15 Features:\")\n",
        "        print(feature_imp_df.head(15).to_string(index=False))\n",
        "        \n",
        "        # Save to CSV\n",
        "        safe_name = model_name.replace(' ', '_').replace('(', '').replace(')', '')\n",
        "        feature_imp_df.to_csv(f'feature_importance_{safe_name}.csv', index=False)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Coefficients for Logistic Regression\n",
        "if 'Logistic Regression' in models:\n",
        "    lr_model = models['Logistic Regression']\n",
        "    if hasattr(lr_model, 'coef_'):\n",
        "        coef_df = pd.DataFrame({\n",
        "            'feature': X_train_df.columns,\n",
        "            'coefficient': lr_model.coef_[0]\n",
        "        }).sort_values('coefficient', key=abs, ascending=False)\n",
        "        \n",
        "        print(\"Logistic Regression - Top 20 Coefficients (by absolute value):\")\n",
        "        print(\"=\" * 80)\n",
        "        print(coef_df.head(20).to_string(index=False))\n",
        "        \n",
        "        coef_df.to_csv('logistic_regression_coefficients.csv', index=False)\n",
        "        print(\"\\nCoefficients saved to 'logistic_regression_coefficients.csv'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SHAP analysis placeholder\n",
        "print(\"SHAP Analysis Setup:\")\n",
        "print(\"=\" * 80)\n",
        "print(\"\\nTo perform SHAP analysis, install shap and run:\")\n",
        "print(\"\\n```python\")\n",
        "print(\"import shap\")\n",
        "print(\"\\n# For tree models:\")\n",
        "print(f\"explainer = shap.TreeExplainer({best_model_name})\")\n",
        "print(f\"shap_values = explainer.shap_values(X_val_df.iloc[:100])  # Sample for speed\")\n",
        "print(f\"shap.summary_plot(shap_values, X_val_df.iloc[:100])\")\n",
        "print(\"\\n# For other models:\")\n",
        "print(f\"explainer = shap.KernelExplainer({best_model_name}.predict_proba, X_val_df.iloc[:100])\")\n",
        "print(f\"shap_values = explainer.shap_values(X_val_df.iloc[:100])\")\n",
        "print(\"```\")\n",
        "print(\"\\nNote: Store the trained model and feature matrix for SHAP analysis.\")\n",
        "\n",
        "# Save model and data for SHAP\n",
        "shap_data = {\n",
        "    'model': best_model,\n",
        "    'X_val_sample': X_val_df.iloc[:100].values,  # Sample for SHAP\n",
        "    'feature_names': X_train_df.columns.tolist()\n",
        "}\n",
        "\n",
        "joblib.dump(shap_data, 'shap_data.joblib')\n",
        "print(\"\\nModel and sample data saved to 'shap_data.joblib' for SHAP analysis.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "This notebook has:\n",
        "1. ✅ Loaded and validated preprocessed data\n",
        "2. ✅ Implemented revenue calculation and threshold optimization\n",
        "3. ✅ Trained multiple models (Logistic Regression, Random Forest, Gradient Boosting, KNN, XGBoost/HistGB)\n",
        "4. ✅ Performed hyperparameter tuning with Optuna (optimizing for revenue)\n",
        "5. ✅ Selected best model based on validation revenue\n",
        "6. ✅ Generated test predictions and submission file\n",
        "7. ✅ Extracted feature importances and interpretability hooks\n",
        "\n",
        "**Key Outputs:**\n",
        "- `best_model.joblib`: Trained best model\n",
        "- `best_threshold.json`: Optimal threshold\n",
        "- `submission.csv`: Test predictions\n",
        "- `model_comparison.csv`: Comparison of all models\n",
        "- `feature_importance_*.csv`: Feature importances for tree models\n",
        "- `logistic_regression_coefficients.csv`: Coefficients for logistic regression\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
